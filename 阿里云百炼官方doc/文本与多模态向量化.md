向量化（Embedding）
更新时间：2025-10-22 17:04:46
向量化模型可将文本、图像、视频等数据转换为数值向量，用于语义搜索、推荐、聚类、分类、异常检测等下游任务。
准备工作
您需要已获取API Key并配置API Key到环境变量。如果通过OpenAI SDK或DashScope SDK进行调用，还需要安装SDK。
获取Embedding
文本信息向量化
调用API时，需在请求中同时指定要向量化的文本内容和所使用的模型名称（如 text-embedding-v4）
OpenAI兼容接口-Python
```python
import os
from openai import OpenAI

input_text = "衣服的质量杠杠的"

client = OpenAI(
    # 若没有配置环境变量，请用阿里云百炼API Key将下行替换为：api_key="sk-xxx",
    # 新加坡和北京地域的API Key不同。获取API Key：https://help.aliyun.com/zh/model-studio/get-api-key
    api_key=os.getenv("DASHSCOPE_API_KEY"),  
    # 以下是北京地域base-url，如果使用新加坡地域的模型，需要将base_url替换为：https://dashscope-intl.aliyuncs.com/compatible-mode/v1
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
)

completion = client.embeddings.create(
    model="text-embedding-v4",
    input=input_text
)

print(completion.model_dump_json())
```

DashScope-Python
```python
import dashscope
from http import HTTPStatus
# 若使用新加坡地域的模型，请取消以下注释
# dashscope.base_http_api_url = "https://dashscope-intl.aliyuncs.com/api/v1"
input_text = "衣服的质量杠杠的"
resp = dashscope.TextEmbedding.call(
    model="text-embedding-v4",
    input=input_text,
)

if resp.status_code == HTTPStatus.OK:
    print(resp)
```

多模态向量化
多模态向量化目前仅支持通过DashScope SDK及API调用模型。
```python
import dashscope
import json
from http import HTTPStatus

# 输入可以是视频
# video = "https://help-static-aliyun-doc.aliyuncs.com/file-manage-files/zh-CN/20250107/lbcemt/new+video.mp4"
# input = [{'video': video}]
# 或图片
image = "https://dashscope.oss-cn-beijing.aliyuncs.com/images/256_1.png"
input = [{'image': image}]
resp = dashscope.MultiModalEmbedding.call(
    model="tongyi-embedding-vision-plus",
    input=input
)

print(json.dumps(resp.output, indent=4))
    
```

模型选择
选择合适的模型取决于您的输入数据类型和应用场景。

处理纯文本或代码：推荐使用 text-embedding-v4。它是当前性能最强的模型，支持任务指令（instruct）、稀疏向量等高级功能，能覆盖绝大多数文本处理场景。

处理多模态内容：

统一多模态向量：若要将单模态或混合模态输入表征为统一向量，适用于跨模态检索、图搜等场景，可使用 qwen2.5-vl-embedding。例如，输入一张衬衫图片并附加文本“找相似风格但更显年轻的款式”，模型能将图像和文本指令融合成一个向量进行理解。

独立向量：若要为每个输入（如图片和其对应的文字标题）生成独立的向量，可选择 tongyi-embedding-vision-plus 、 tongyi-embedding-vision-flash或通用多模态模型multimodal-embedding-v1为每个输入部分（图片、文字）生成一个独立的向量。

处理大规模数据：若您需要处理大规模、非实时的文本数据，建议使用 text-embedding-v4 并结合 OpenAI兼容-Batch调用，以显著降低成本。

下表包含所有可用向量化模型的详细规格。

文本向量
北京
模型名称

向量维度

批次大小

单次最大处理Token数

单价（每千输入Token）

免费额度（注）

支持语种

text-embedding-v4

属于Qwen3-Embedding系列
2,048、1,536、1,024（默认）、768、512、256、128、64

10

8,192

0.0005元

Batch接口调用：0.00025元

100万Token

有效期：百炼开通后90天内

中文、英语、西班牙语、法语、葡萄牙语、印尼语、日语、韩语、德语、俄罗斯语等100+主流语种

text-embedding-v3

1,024（默认）、768、512、256、128或64

0.0005元

Batch接口调用：0.00025元

各50万Token

有效期：百炼开通后90天内

中文、英语、西班牙语、法语、葡萄牙语、印尼语、日语、韩语、德语、俄罗斯语等50+主流语种

text-embedding-v2

1,536

25

2,048

0.0007元

Batch接口调用：0.00035元

中文、英语、西班牙语、法语、葡萄牙语、印尼语、日语、韩语、德语、俄罗斯语

text-embedding-v1

中文、英语、西班牙语、法语、葡萄牙语、印尼语

text-embedding-async-v2

100,000

0.0007元

2000万Token

有效期：百炼开通后90天内

中文、英语、西班牙语、法语、葡萄牙语、印尼语、日语、韩语、德语、俄罗斯语

text-embedding-async-v1

中文、英语、西班牙语、法语、葡萄牙语、印尼语

说明
批次大小指单次API调用中能处理的文本数量上限。例如，text-embedding-v4的批次大小为10，意味着一次请求最多可传入10个文本进行向量化。这个限制适用于：

字符串数组输入：数组最多包含10个元素。

文件输入：文本文件最多包含10行文本。

多模态向量
模型根据用户的输入生成连续向量，这些输入可以是文本、图片或视频。适用于视频分类、图像分类、图文检索，以文/图搜图，以文/图搜视频等任务场景。

接口支持单段文本、单张图片或单个视频文件的上传，也允许不同类型组合（如文本+图片），部分模型支持同类型内容的多个输入（如多张图片），请参考具体模型的限制说明。







模型名称

向量维度

文本长度限制

图片限制

视频片限制

单价（每千输入Token）

免费额度（注）

qwen2.5-vl-embedding

2048, 1024, 768, 512

32,000 Token

≤5MB,

1张

≤50MB

图片/视频：0.0018元

文本：0.0007元

100万Token

有效期：百炼开通后90天内

tongyi-embedding-vision-plus

1,152

1,024 Token

≤3MB,

≤8张

≤10MB

0.0005元

tongyi-embedding-vision-flash

768

1,024 Token

≤3MB,

≤8张

≤10MB

图片/视频：0.0002元

文本：0.0005元

multimodal-embedding-v1

1,024

512 Token

≤3MB,

1张

≤10MB

免费试用

无Token额度限制

输入格式与语种限制：




模型

文本

图片

视频

qwen2.5-vl-embedding

支持中、英、日、韩、法、德等11种语言

JPEG, PNG, WEBP, BMP, TIFF, ICO, DIB, ICNS, SGI（支持URL或Base64）

MP4, AVI, MOV（仅支持URL）

其他多模态模型

中/英文

JPG, PNG, BMP (支持URL或Base64)

MP4, MPEG, AVI, MOV, MPG, WEBM, AVI, FLV, MKV（仅支持URL）